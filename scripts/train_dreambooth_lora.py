import os
from pathlib import Path
from PIL import Image
import torch
from tqdm import tqdm
from transformers import CLIPTokenizer
from diffusers import (
    StableDiffusionPipeline,
    DDPMScheduler,
    AutoencoderKL,
    UNet2DConditionModel,
)
from peft import LoraConfig, get_peft_model

# ========== NASTAVENÃ ========== #
model_id = "runwayml/stable-diffusion-v1-5"
instance_prompt = "a photo of igloo penguin"
output_dir = "outputs/igloonet_penguin_lora_v2"
data_dir = "data/images_augmented"

resolution = 512
batch_size = 1
learning_rate = 1e-4
num_epochs = 4

# ========== MODELY ========== #
print("ğŸ“¦ NaÄÃ­tÃ¡m model...")

tokenizer = CLIPTokenizer.from_pretrained(model_id, subfolder="tokenizer")
vae = AutoencoderKL.from_pretrained(model_id, subfolder="vae").to("cuda", dtype=torch.float16)
unet = UNet2DConditionModel.from_pretrained(model_id, subfolder="unet").to("cuda", dtype=torch.float16)

# ========== PÅ˜IDÃNÃ LoRA ========== #
print("ğŸ§  PÅ™idÃ¡vÃ¡m LoRA vÃ¡hy do UNet...")

lora_config = LoraConfig(
    r=4,
    lora_alpha=16,
    target_modules=["to_q", "to_k", "to_v", "to_out.0"],
    bias="none",
    task_type="UNET",
)
unet = get_peft_model(unet, lora_config)

# ========== DATA ========== #
print(f"ğŸ“ NaÄÃ­tÃ¡m obrÃ¡zky ze sloÅ¾ky: {data_dir}")
image_paths = list(Path(data_dir).glob("*.png"))
print(f"ğŸ–¼ï¸ PoÄet nalezenÃ½ch obrÃ¡zkÅ¯: {len(image_paths)}")

if not image_paths:
    raise ValueError("Nenalezeny Å¾Ã¡dnÃ© obrÃ¡zky pro trÃ©nink.")

def load_images():
    images = []
    for path in image_paths:
        img = Image.open(path).convert("RGB").resize((resolution, resolution))
        images.append(torch.tensor(img, dtype=torch.float32).permute(2, 0, 1) / 255.0)
    return images

train_images = load_images()
print(f"âœ… NahrÃ¡no {len(train_images)} obrÃ¡zkÅ¯ pro trÃ©nink.")

# ========== TRÃ‰NINK ========== #
print("ğŸš€ SpouÅ¡tÃ­m trÃ©nink...")

optimizer = torch.optim.AdamW(unet.parameters(), lr=learning_rate)
scheduler = DDPMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule="scaled_linear")

unet.train()
for epoch in range(num_epochs):
    print(f"ğŸ§ª Epoch {epoch + 1}/{num_epochs}")
    for img in tqdm(train_images):
        pixel_values = img.unsqueeze(0).to("cuda", dtype=torch.float16)

        with torch.no_grad():
            latents = vae.encode(pixel_values).latent_dist.sample() * 0.18215

        noise = torch.randn_like(latents)
        timesteps = torch.randint(0, 1000, (1,), device="cuda").long()
        noisy_latents = scheduler.add_noise(latents, noise, timesteps)

        encoder_hidden_states = tokenizer(
            instance_prompt, return_tensors="pt"
        ).input_ids.to("cuda")

        model_pred = unet(noisy_latents, timesteps, encoder_hidden_states=encoder_hidden_states).sample
        loss = torch.nn.functional.mse_loss(model_pred, noise)
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()

    print(f"âœ… Epoch {epoch + 1} hotovÃ¡!")

# ========== ULOÅ½ENÃ ========== #
print(f"ğŸ’¾ UklÃ¡dÃ¡m LoRA vÃ¡hy do sloÅ¾ky: {output_dir}")
os.makedirs(output_dir, exist_ok=True)
unet.save_pretrained(output_dir)

print("\nâœ… TrÃ©nink dokonÄen! Lovec Å terbin je pÅ™ipraven generovat tuÄÅˆÃ¡ky.")